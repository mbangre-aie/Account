play.modules.enabled += com.example.account.impl.AccountModule
play.modules.enabled += com.lightbend.lagom.javadsl.persistence.jdbc.JdbcPersistenceModule

db.default {
  driver = "org.postgresql.Driver"
  url = "jdbc:postgresql://localhost:5432/account_poc_write_side"
  username = "postgres"
  password = "admin"
  async-executor {
    # number of objects that can be queued by the async executor
    queueSize = 10000
    # 5 * number of cores
    numThreads = 5
    # same as number of threads
    minConnections = 5
    # same as number of threads
    maxConnections = 5
    # if true, a Mbean for AsyncExecutor will be registered
    registerMbeans = false
  }
  # Hikari is the default connection pool and it's fine-tuned to use the same
  # values for minimum and maximum connections as defined for the async-executor above
  hikaricp {
    minimumIdle = ${db.default.async-executor.minConnections}
    maximumPoolSize = ${db.default.async-executor.maxConnections}
    # maxLifetime = 600000
    poolName = promotionsWriteSide
    leakDetectionThreshold = 2000
  }
  # Alternatively, BoneCP can be used instead of Hikari.
  # More information on how to switch to BoneCP can be found here:
  # https://www.playframework.com/documentation/2.6.x/ScalaDatabase#Selecting-and-configuring-the-connection-pool
  #
  # The settings below configured it to use the same
  # values for minimum and maximum connections as defined for the async-executor above
  bonecp {
    # the pool partition count
    partitionCount = 1
    # the value below is dependent on the partitionCount
    # it must be equal or less than async-executor.minConnections / partitionCount
    minConnectionsPerPartition = ${db.default.async-executor.minConnections}
    # the value below is dependent on the partitionCount
    # it must be equal or less than async-executor.maxConnections / partitionCount
    maxConnectionsPerPartition = ${db.default.async-executor.maxConnections}
  }

}
# JPA read-side configuration.
db.readside {
  driver = "org.postgresql.Driver"
  url = "jdbc:postgresql://localhost:5432/account_poc_read_side"
  username = "postgres"
  password = "admin"

  jndiDbName = readside

  async-executor {
    # number of objects that can be queued by the async executor
    queueSize = 10000
    # 5 * number of cores
    numThreads = 5
    # same as number of threads
    minConnections = 5
    # same as number of threads
    maxConnections = 5
    # if true, a Mbean for AsyncExecutor will be registered
    registerMbeans = false
  }
  # Hikari is the default connection pool and it's fine-tuned to use the same
  # values for minimum and maximum connections as defined for the async-executor above
  hikaricp {
    minimumIdle = ${db.readside.async-executor.minConnections}
    maximumPoolSize = ${db.readside.async-executor.maxConnections}
    poolName = promotionsReadSide
    leakDetectionThreshold = 2000
  }
  # Alternatively, BoneCP can be used instead of Hikari.
  # More information on how to switch to BoneCP can be found here:
  # https://www.playframework.com/documentation/2.6.x/ScalaDatabase#Selecting-and-configuring-the-connection-pool
  #
  # The settings below configured it to use the same
  # values for minimum and maximum connections as defined for the async-executor above
  bonecp {
    # the pool partition count
    partitionCount = 1
    # the value below is dependent on the partitionCount
    # it must be equal or less than async-executor.minConnections / partitionCount
    minConnectionsPerPartition = ${db.readside.async-executor.minConnections}
    # the value below is dependent on the partitionCount
    # it must be equal or less than async-executor.maxConnections / partitionCount
    maxConnectionsPerPartition = ${db.readside.async-executor.maxConnections}
  }
}
jdbc-defaults.slick.profile = "slick.jdbc.PostgresProfile$"

# The properties below override Lagom default configuration with the recommended values for newclass projects.
#
# Lagom has not yet made these settings the defaults for backward-compatibility reasons.

# Prefer 'ddata' over 'persistence' to share cluster sharding state for newclass projects.
# See https://doc.akka.io/docs/akka/current/cluster-sharding.html#distributed-data-vs-persistence-mode
akka.cluster.sharding.state-store-mode = ddata
# Enable the serializer provided in Akka 2.5.8+ for akka.Done and other internal
# messages to avoid the use of Java serialization.
akka.actor.serialization-bindings {
  "akka.Done" = akka-misc
  "akka.actor.Address" = akka-misc
  "akka.remote.UniqueAddress" = akka-misc
}
lagom.persistence {
  jdbc.create-tables.auto = false
  read-side.jdbc {
    slick {
      jndiDbName = ${db.readside.jndiDbName}
    }
  }
  # As a rule of thumb, the number of shards should be a factor ten greater
  # than the planned maximum number of cluster nodes. Less shards than number
  # of nodes will result in that some nodes will not host any shards. Too many
  # shards will result in less efficient management of the shards, e.g.
  # rebalancing overhead, and increased latency because the coordinator is
  # involved in the routing of the first message for each shard. The value
  # must be the same on all nodes in a running cluster. It can be changed
  # after stopping all nodes in the cluster.
  max-number-of-shards = 100

  # Persistent entities saves snapshots after this number of persistent
  # events. Snapshots are used to reduce recovery times.
  # It may be configured to "off" to disable snapshots.
  snapshot-after = 100

  # A persistent entity is passivated automatically if it does not receive
  # any messages during this timeout. Passivation is performed to reduce
  # memory consumption. Objects referenced by the entity can be garbage
  # collected after passivation. Next message will activate the entity
  # again, which will recover its state from persistent storage. Set to 0
  # to disable passivation - this should only be done when the number of
  # entities is bounded and their state, sharded across the cluster, will
  # fit in memory.
  passivate-after-idle-timeout = 120s

  # Specifies that entities run on cluster nodes with a specific role.
  # If the role is not specified (or empty) all nodes in the cluster are used.
  # The entities can still be accessed from other nodes.
  run-entities-on-role = ""

  # Default timeout for PersistentEntityRef.ask replies.
  ask-timeout = 30s

  dispatcher {
    type = Dispatcher
    executor = "thread-pool-executor"
    thread-pool-executor {
      fixed-pool-size = 16
    }
    throughput = 1
  }
}

# The name of the Kafka service to look up out of the service locator.
# If this is an empty string, then a service locator lookup will not be done,
# and the brokers configuration will be used instead.
lagom.broker.kafka.service-name = ""

# The URLs of the Kafka brokers. Separate each URL with a comma.
# This will be ignored if the service-name configuration is non empty.
lagom.broker.kafka.brokers = "localhost:9092"

account.retentionCriteria.numberOfEvents = 3
account.retentionCriteria.keepNumberOfSnapshots = 2



